# early cuts from intro materials

Specifically, I believe that AI, machine learning and related technologies are on the verge of producing a disruptive change in how we identify and treat psychiatric disorders.  

There are a number of related efforts in this area but I want to highlight two efforts that are far enough along to generate some excitement.

Talk about each briefly



I want to propose that a key feature of these new approaches is that they SCALE very well to increase capacity to provide interventions.  And with adequate SCALE, their effectiveness can be modest and they will still provide substantial aggregate benefit to reduce suffering from a population  health perspective.

Can address: 
cost [b/c they are inexpensive to implement and may reduce need of expensive time from therapists]

stigma (private, self directed)

Aid early diagnosis (efficient/massive diagnosis)

Improve effectiveness (could improve interventions by adapting to the person and moment in time)

I also want to emphasize that I am not talking about replacing human therapists.    These are primarily new tools that clinicians can use to supplement or augment the mental health services that they are providing.


<!--Let me start with some sobering statements.  We have a mental healthcare crisis in the United States.  Our need for mental health services is alarmingly high and the practical capacity of our healthcare system to meet this need is woefully inadequate.-->

<!--We all know this story because its the story of our family members, our friends, for some of us, ourselves.-->


# VA materials from focused draft
/va-dtx.png
<!-- Draft image;  Need to consider which apps to highlight. Consider apps featured in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6087876/#!po=78.1250; apps are here: https://mobile.va.gov/appstore/all -->

Our nation's largest integrated health care system, the Veterans Health Administration, has been at the forefront of this implementation effort.  

The VA has developed and distributed a suite of 20 digital therapeutics that provide evidence-based treatments and self-management strategies for mental illness.  

These digital therapeutics are targeted at veterans but the VA makes them freely available to everyone.  




# Pitfalls cuts

These goals are possible, if not today, in the coming years as we continue to develop smart digital therapeutics. However, there are no guarantees and numerous pitfalls exist that we must avoid. 

To my eye, the greatest obstacles emerge from tensions among three related issues:

 1. How we regulate digital therapeutics to assure their safety and effectiveness, 
 2. How we distribute them to patients
 3. And who pays for them

---

<!-- Wild west image -->
Currently, the world of digital health more broadly is a bit like the Wild West.  There are over 350k digital health apps available for download in app stores on our smartphones. Many of these apps have little or no evidence of their effectiveness.  And privacy risks become paramount as more and more apps incorporate personal sensing of our sensitive data.

Fortunately, the FDA has begun to recognize the need for regulation and to clarify its planned approach.  The FDA does not plan to regulate the broad category of digital health apps that are intended to maintain or encourage a healthy
lifestyle.  However, they do plan to provide regulatory oversight for the narrower class of digital therapeutics that are used to diagnose, treat or manage disease including mental illness.  In fact, in 2018 the FDA cleared the first digital therapeutic for substance use disorders based in part on evidence of its effectiveness.  

This is an important first step but FDA oversight is not sufficient because patients may not always be aware of their guidance or the subtle distinctions between a digital health app and a digital therapeutic.

---

Mental healthcare providers may serve as an important and trustworthy conduit of safe and effective digital therapeutics to their patients. However, if digital therapeutics are only available through healthcare providers we may miss the opportunity to address mental health disparities among vulnerable groups who are uninsured or don't otherwise have access to healthcare.

---

The VA offers an interesting model where they provide their own digital therapeutics directly through the VA website, but free to everyone.  This allows them to recommend and broadly distribute digital therapeutics that are safe and effective.  

However, as smart digital therapeutics become more expensive to develop, evaluate, and maintain, it is not clear who will pay these expenses if they are freely distributed.  

Some of the most promising digital therapeutics for substance use disorders have resulted from academic/commercial partnerships but these therapeutics are not free.  

---

We also need to tackle issues that arise from scale.  Digital therapeutics are highly scalable given that many of their supports are not dependent on human clinicians but software.  This scale can address key issues with access and availability that are serious problems for traditional mental healthcare with human clinicians.  Their scale can also control mental healthcare costs.  

Unfortunately, scale comes with risks as well. As digital therapeutics scale, there may economic pressures to limit access to or even replace human clinicians.  We must resist this impulse that could compromise outcomes in favor of lower costs.

The scale of digital therapeutics may also further homogenize mental healthcare by providing the same interventions to all patients.  To be clear, this is already a problem for traditional mental healthcare interventions which have primarily been developed and evaluated with white patients.  However, to the degree that there is recognition of this problem and some diversity across human clinicians, their interventions are tailored at times to be culturally appropriate for communities of color and other minority groups.  We have an opportunity to intentionally recruit clinicians of color to re-imagine these new and modified interventions that are delivered by digital therapeutics so that they are acceptable for everyone. 

# Digital agents and acceptability
---

/woebot.png

<!-- Need to simplify the language here-->

On the more leading edge, there has been recent rapid developments of virtual relational agents that use natural language processing to communicate more naturally while providing support for mental illnesses.

For example, Woebot is a chatbot designed by Stanford-trained researchers and psychologists.  Woebot uses brief, text-based conversations and tools based on CBT and related interventions to provide psycho-education and guided support.  

---
By their very nature, all of these digital therapeutics on smartphones can be accessible and available, everywhere you go, 24/7.  But, equally important, many patients appear to find digital therapeutics acceptable.

For example, the VAs digital therapeutic for post-traumatic stress disorder, a single app in their suite of 20 digital therapeutics, has been downloaded more than a half million times across 115 countries.  And over 60% of its users engaged with it on multiple occasions. 

<!-- in the last week of March 2020 more than 750,000 Apple iOS users downloaded MBI apps (Kellen & Saxena, 2020)  https://aisel.aisnet.org/iceb2020/43/ -->

---
<!--Similar or modify a woebot?-->
/bot_bond.png

In fact, digital therapeutics may be more than just acceptable.  When chatbots or other virtual agents are included, patients may form real connections with them.  

In a recent study, over 36,000 adults who received digital cognitive behavioral therapy from Woebot described their therapeutic bond in terms typically reserved only for human therapists.  Patients frequently endorsed statements like:

* Woebot likes me.
* Woebot and I respect each other.
* Woebot appreciates me.
* Woebot cares about me even when I do things that they do not approve of.

---

Other studies has observed that patients self-disclose more, display their sadness more,  and do less impression management when interacting with virtual agents rather than human therapists.

<!--Alison Darcy, the developer of Woebot, has noted that this ability to establish a bond, and to do so with millions of people simultaneously, is the secret to unlocking the  vast potential of digital therapeutics-->


# Full smartphone demograpics


```
Smartphone Ownership by Key Demographics 

White	            85%
Black	            83%
Hispanic	        85%

Urban	            89%
Suburban	        84%
Rural	            80%

Less than $30,000	76%
$30,000-$49,999	    83%
$50,000-$74,999	    85%
$75,000+	        96%
```



# Personal sensing examples

Behind me is a wide view of my moment by moment location detected by my smartphone over a month when we were first experimenting with this personal sensing method.  You can see the paths that I traveled, with movement by car in yellow and running in blue.  The points in red indicate places that I stopped to visit for at least a few minutes.  And although not displayed here, we know the day and exact time that I was at each location.  

You can immediately see that I am runner, with long runs leaving from downtown Madison and frequent trail runs in the county and state parts to the west and northwest.  Running makes an important contribution to both my physical and mental health. You could learn these patterns and also detect if events in my life disrupted these patterns.

---

/gps_2.png

Zooming in to the Madison isthmus, you can immediately see dense clusters of red dots indicating places visited near my home and where I work at the University of Wisconsin.  You can see that I drive my children clockwise around the lake each morning to their elementary school.  And you could detect those stressful mornings when getting my young kids dressed and fed didn't go as planned and we were late, sometimes very late, to school!

You can see my daily running commute to and from my office.  From this, you can observe the long days, and short days, at the office.   

If you probed the red dots indicating the places I visit, you would find the restaurants, bars, and coffee shops I frequent to eat, drink and socialize.  You could identify the homes of my friends, and the stores where I shop.  You could see when my life was filled with healthy and rewarding social activities.  You might also see periods of social isolation during bouts with depression or high stress.

<!--Can still tune these examples above-->
<!-- time in hospital-->   <!--time away from work and running-->  <!--COVID image?-->
<!--specific restaurants or cafes if humorous or personalizing-->

---

/text_messages.png
<!--Will edit for copyright and to more clearly convey stressor of having phone stolen-->

We also collect smartphone communications logs and text message content.  And no, I don't plan to show you my actual text messages!

But imagine what you could learn about me if you knew the patterns of my communications - Who I was calling, when I made those calls, and even the content of what I sent and received by text message, in other words, my own words.  You might see the late sleepless nights, particularly if you also logged all the use of my smartphone.  You might see my messages sharing joys or stressors, like when my expensive phone was stolen.  Natural language processing could be used to extract the meaning of my words and use this to make inferences about my recent experiences, emotional state, and even psychiatric symptoms. 

---

These raw location and communications data that we sense directly from the smartphone are powerful signals for prediction right out of the box. But personal sensing draws additional power from repeated measurements of the same person over days, weeks, months, and even years.  It is the change in our patterns that are often most meaningful.  We stop going to work briefly for a vacation or we stop for a longer period when we lose our job. We stop or restart going to AA meetings or to our therapist.  

Or we start late night calls and text messages after a period of successful recovery when we had established more healthy behaviors and lifestyle. 

<!--consider better examples-->
<!-- GEF: consider personal example of fewer/no runs would be a big red flag for you. Also could use this to get across the idea that you already know the impact not running has on you, but there may be other things you wouldn't be able to know just intuitively-->
---

<!--Slide: Text message with "Mom" vs. "Joe Party-Party".-->

/mom_raw.png

We can engineer even more sensitive predictive features from these data by discovering what these people and places mean to us.

For example, this very same text message thread behind me may indicate quite different risk for relapse when sent to your mother, who supports your recovery, vs. a friend who wants you back in the bar with them. <!-- better description? "...who wants you back at their all-night parties"-->.  

We can gather this information quickly and with little burden to the patient by pushing out a few key questions to their smartphone about their frequent contacts and locations over the first couple of months of their use of the digital therapeutic. It turns out that we are all creatures of habit, and we only have a small number of important people and places in our lives.

We can identify the specific people and places that make us happy or sad or stressed, those that we perceive support our recovery and those who undermine it. Armed with this information, we can gain more precise insights into your patterns of movements and social communications. <!-- GEF: i think you can delete the next two sentences and go straight to patterns changing--> Are they healthy or unhealthy, rewarding and rich, or stressful or isolating.  Do the people you surround yourself with support your recovery or tempt you back to old ways.  And how have these patterns changed, for better or for worse, over recent days, weeks, and months.  

<!--need pronouns and consistent focus on target we are sensing-->
---

<!-- Maybe a map with clear indications of my house, my office, and a few key public bars and health care facilities??  -->

We can further flesh out the meaning for specific places passively using their spacial-temporal features and publicly available map data that are often sufficient to identify our home, our workplace, and commercial spaces, like bars, restaurants, liquor stores, healthcare facilities and the like.  

# Personal sensing examples

We could pinpoint the day of my mom's car accident, when my dad is suddenly spending all day, into the late evening, at St John's Hospital, and returning home for only a few hours of sleep each night.  If this happened now, there would also be frantic text messages to keep family and friends informed

---

If we were sensing my life about a year ago, we would see my 8 days as an inpatient at UW Hospital following a rare and life-threatening drug reaction to an antibiotic I had received.  We would see my frantic text messages to keep family and friends informed.  After I was discharged, we would notice my sleepless nights caused in part by high doses of corticosteroids.  The app might know that I had started dabbling with meditation and it could recommend I meditate at night to help me sleep better.  Continue with running stopped, depression, nudge me to start again

# Ads
On a slightly more embarrassing note, after having a vasectomy a few years ago, I immediately started receiving ads for ice packs and "tighty-whitey" supportive underwear.   But those worked too!


# Privacy

I am encouraged that in our research, participants generally find it acceptable to share this sensitive information with us.  This may be because they recognize that other apps on their phone already collect similar information but our digital therapeutics will use their information to improve their mental health rather than profit off it by selling them products.  If we share our personal data, we should benefit from it directly. 
