# Mental Healthcare at our Fingertips and within our Grasp


## The Mental Healthcare Crisis

When I was still relatively young, my mother lost control of her car when it hit a patch of ice two days before Christmas.  Her car spun off the road, her seat collapsed, and she experienced a traumatic brain injury.  She survived but she never recovered even to the point of recognizing my sister and me.  She required full-time care for the rest of her life.  

---

/dad.jpg

My dad is a good man.  He devotedly stayed home for 25 years rather than work so that he could care for my mom at home rather than commit her to an institution.     

My dad is a good man who he has struggled with his use of alcohol for his entire adult life. At times, it was in the background of our lives.  At other times, it was severe. He is almost 80 years old now and he has never received any treatment.  

It breaks my heart, but it is not surprising.  And I expect that many of you have similar stories about family and friends who didn't receive treatment.

---

We have a mental health crisis in the U.S. and it is a crisis of **unmet** high need because our delivery of mental healthcare is deeply flawed.

In 2019, well over half of the 52 million Americans with an active mental illness did not receive **any** treatment.  **More than half**!  

And for those suffering with a substance use disorder - like my dad - it was worse still.  **9 out of 10 without any treatment**

This failure to treat has tragic consequences.  In the past year alone, almost **100,000 people** have died from drug overdoses.  

---

/victor.jpg

And these are not just big numbers, they are real people.

One of them was Victor Kittleson, the 29 year-old brother of one of my graduate students, who died from an opioid overdose this past summer.

---

This failure to treat is even more troubling for vulnerable groups.  African American & Hispanic Americans receive mental healthcare services at about half the rate of whites.  

And similar mental healthcare disparities exist for people living in rural areas and for those with lower incomes.

---

**Access** , **acceptability**, and **availability** - these are the factors that undermine our mental healthcare system.  

---

While caring for my mom at home, my dad's **access** to mental healthcare was limited by its high cost without health insurance through a job.  

---

/psychologist_heatmap.png
<!--Have Kortney edit colors in figure to be standard heat map with clearer legend and title-->

But geography also impacts access.  For example, consider the **access** to mental healthcare for the farmer in rural Kansas, when more than 90% of all psychologists and psychiatrists and 80% of social workers work exclusively in metropolitan areas and predominately on the coasts.  

---

Even if my dad had had access to treatment, it likely wouldn’t have been **acceptable** to him. Like many men of his generation, asking for help from others and sharing personal problems wasn’t his strong suit. 

But **even our family** never discussed it.  It was the elephant in the room.  Making ourselves vulnerable to therapists and to each other is hard.  

And it is harder still because of the stigma that surrounds mental illness even today.

---

Mental healthcare services are often not **available** when we need them most.  Many well-regarded therapists have long wait lists that can delay the start of treatment for months.  

And once we make it off the wait list, treatment still often involves weekly, monthly, or even less frequent appointments with a therapist.  But our mental health needs aren't limited to these pre-scheduled appointments.  

Would a therapist have been available to my dad at his moments of greatest need - when he lost a job due to downsizing, or shortly after my mom's car accident, or on the many dark mornings when he woke up with his hands shaking and had to decide if he was going to drink again to steady them? 

## Digital Therapeutics

**Access, acceptability, and availability** - these issues are undermining the treatment capacity of our mental healthcare system and leaving millions without treatment when they need it most.  

Fortunately, digital therapeutics, and in particular, digital therapeutics **delivered on smartphones and made smarter still by personal sensing technologies**, are now emerging to target these very same three issues.  

___

But let me pause for a moment.  I want to be very clear on one point before we move forward.  I do not believe or hope that digital therapeutics will replace human therapists. 
  
Therapists will always be needed for what they do uniquely well.  But we simply need more than they can provide alone.  Digital therapeutics can provide that "more."

---

So what are digital therapeutics?

Digital therapeutics are software programs or "apps" that are designed to prevent, manage, or treat disease, including mental illness. 

---

Digital therapeutics are delivered to patients on their smartphones and this is the key to their accessibility and availability.

Today, 85% of adults in the U.S. own smartphones.  And equally important, ownership is similarly high regardless of race, ethnicity, income, and geography.

Most of us now carry these pocket-sized, powerful computers with us everywhere we go.

And its this widespread use of smartphones that allows digital therapeutics to provide support
* 24 hours a day, 
* 7 days a week, 
* every day of the year,
* regardless of where we live

___

Some of the best examples of these digital therapeutics have been developed to target substance use disorders.  These apps include multiple supports for patients during their treatment and recovery.

For example, if you need formal treatments, they have you covered.  The apps include cognitive behavioral therapy and mindfulness-based relapse prevention

If you need peer support, the apps include discussion forums with other patients.

The apps can also help you locate self-help groups like AA or NA in your community.

The apps can help you track your symptoms over time and your symptoms can even be shared with your therapist if you opt to do so through the apps' clinician dashboard.

And these are just a few examples of the many supports that are possible to provide in these digital therapeutic apps.  

---

Of course, all of this would be meaningless if digital therapeutics were not effective.

But they are.  

For example, patients using digital therapeutics have almost double the odds of being abstinent from alcohol or other drugs.

These increases in abstinence from using digital therapeutics are observed not only when compared to patients on wait lists, who have yet to gained access to treatment but also when digital therapeutics are added on top of traditional treatments for substance use disorders.

And these benefits are durable - they have been documented up to 12 months after the start of treatment.  

---

This is a big deal.  The magnitude of these benefits are meaningful already, even when we only think about a single patient using the app.  

But their true power is in their scale, when the benefits from these apps are multiplied because they are provided simultaneously to millions of people in need.  

This is how we can increase the treatment capacity of our mental healthcare system and see substantial improvement in public mental health overall.  
 
## Smarter Digital Therapeutics with Personal Sensing

/beta.png

<!-- Need to think about "within our grasp" part and how to emphasize if it stays as part of the talk-->

OK, so lets call the apps I have described to you so far, the beta version of digital therapeutics.  Their power arises from easy, 24/7 access to their many supports - their interventions, tools, and services.

---

<!-- Image representing challenge of choosing what to do?  Talk with Kortney about her ideas-->

But this is also their Achilles heel.  As the patient using these apps, you now have to tackle difficult questions like:
 
* When should I use them?
* For how long?
* Which of their various supports are right for me?
* And which are right for me **now**, at this moment in time?

To realize their full potential, the next wave of digital therapeutics must learn to know us better as individuals, not just patients with the same coarse diagnoses and same treatment needs at all times.  

And they will do this through the use of built-in artificial intelligence algorithms that are powered by personal sensing.

<!-- this text doesnt really say that the app needs to recommend treatments-->

---

Although you may not have heard the term "personal sensing" before, you have almost certainly seen it in action.

I'm a running nut, and for me, ads for trail running shoes, the latest running backpacks, or the newest fancy water bottles follow me around everywhere.  
 
This fall, I've been bombarded with ads for books, videos, and classes to improve my public speaking.   Right about now, I am kinda wishing I bought a few.

Currently, personal sensing is used primarily to sell us things.   But we hope to empower people to use their personal data to improve their own mental healthcare.

---

/smartphone.png
<!-- Have Kortney create a similar image.  We dont have copyright to this one.  Just grabbed it off the web-->
<!-- simplify this text and synch with image created by Kortney-->

Personal sensing has been supercharged by smartphones and the data that they passively collect about us as we use them.

We use our smartphones to make phone calls and text messages.  These communications are stored in logs.  We often access and post to our social media accounts from our smartphones.

Smartphone-embedded sensors know our moment-by-moment location and activity level.  Sensors can even detect other people, or at least their smartphones, in our immediate environment.  

Personal sensing involves capturing all this information and using it to understand our recent experiences, preferences, and behaviors.  It can be used to predict how we feel right now, and even how we may feel or behave in the future.  

---

My research team became interested in personal sensing when my colleague Dave Gustafson, the developer of a leading digital therapeutic for substance use disorders, approached us with a simple question. He asked...  

> "Could you predict not only who might be at greatest risk for relapse
> but **precisely when** that relapse might occur and 
> **how best to intervene** to prevent it"  

He had just completed a large study demonstrating the effectiveness of his app. However, he also noticed many of the people who relapsed hadn't used the app in the days leading up that relapse.  And others who relapsed hadn't used the specific supports in the app that he would have thought would be most effective.

He wondered if the benefits of his app could be increased if it knew the person well enough to recognize when they were at greatest risk for relapse and if it was smart enough to recommend the specific supports that would be most effective for them at that moment in time to prevent a relapse.  

This launched us on a new program of research to develop personal sensing algorithms that could be added to digital therapeutic apps to accomplish these goals.

---

/gps_1.png

Let's "look under the hood" so to speak at two of the more revealing personal sensing methods that we are developing to provide you with some intuition about how this works.

Behind me is a wide view of my moment-by-moment location detected by a digital therapeutic app over a month when we were first experimenting with this personal sensing method.  The app recorded the paths that I traveled, with movement by car in yellow and running in blue.  

The points in red indicate places that I stopped to visit for at least a few minutes.  

And although not displayed here, the app knows the days and exact times that I was at each of these locations.  <!--how to indicate this in image?-->

The app can immediately see that I am runner, with long runs leaving from downtown Madison and frequent trail runs in the county and state parks to the west and northwest.

---

/gps_2.png

Zooming in to the Madison isthmus, the app recorded dense clusters of red dots indicating places that I visited near my home and where I work at the University of Wisconsin.  It can see that I drive my children clockwise around the lake each morning to their elementary school.  And it could detect those stressful mornings when getting my young kids dressed and fed didn't go as planned and we were late, sometimes **very late**, to school!

The app recorded my daily running commute to and from my office.  From this, it can observe my longs days, and short days, at the office.   

Looking at the red dots indicating the places I visit, the app can detect the restaurants, bars, and coffee shops where I eat, drink and socialize.  It can use public map data to identify these places and make inferences about what I do there.  

---

/text_messages.png

<!--Will remake for copyright-->

The app also collected my smartphone communications logs and even the content of my text messages.  And no such luck, I don't plan to show you my actual text messages!

But imagine what it learned about me from the patterns of my communications - Who I was calling, when I made those calls, and even the content of what I sent and received by text message, in other words, my own words.  

---

The app can improve its predictions even further by identifying the specific people and places that make us happy or sad or stressed, those that we perceive support our mental health and those who undermine it. 

It can gather this information quickly by asking us a few key questions about our frequent contacts and locations over the first couple of months that we use it.

For example, if my dad was using such an app, it would see that he calls and texts frequently with his friend, Ed.  My dad would report that Ed has been a lifelong source of stability and support.  

Given this, the app would know my dad is doing well when he spends time at Ed's house, when they call and text each other to plan activities, when they go for daily walks along the beach by the Long Island Sound.  

It could also detect when time spent with Ed abruptly stops each fall because Ed spends his winters in Florida.  These months are harder for my dad and he would benefit from more support.

The app could encourage him to reach out to other supportive family and friends during these times.  It could provide him with locations and meeting times for support groups in his community.  He could even be assisted to build community in the discussion forums within the app itself.

If the app knew him well, it might even predict which of these forms of support would be most effective for him.

If he had also received traditional mental healthcare, he might have given permission for the app to share information with his therapist.  His therapist might then increase their support when my dad was more isolated but direct their support preferentially to other patients when my dad was more stable and supported by his healthy friends and family.  

---

In our research studies, we can already use the app to predict if someone will relapse back to drinking **tomorrow** with relatively high accuracy based on personal sensing of their recent past experiences and behaviors.  **This is exciting**.

But these are **preliminary** research studies.  And we started with participants from our local Madison community.  And the samples were predominately white. Personal sensing algorithms trained on these participants would be unlikely to work well with black and brown patients or patients from rural communities.  

For example, we have all seen media reports on how AI facial analysis algorithms trained on images of predominantly light-skinned men fail catastrophically when used to classify even famous dark-skinned women like Oprah Winfrey or Michelle Obama.

We must commit to train our personal sensing algorithms on diverse samples of patients or our algorithms' predictions and recommendations will be biased toward the needs of the majority and we may exacerbate rather than reduce existing mental healthcare disparities. Our current studies now specifically recruit for racial, ethnic, and geographic diversity across the entire United States. 

---

<!--https://www.shutterstock.com/image-photo/young-crazy-surprised-cat-make-big-1058307686-->

/surprised_cat_1.png

I also suspect that at some point, probably about five minutes ago, you also thought: 

> "Holy crap, this is really private information that these apps would collect from me.  Who will have access to it and what will they do with it?"

Most of us are too familiar with recent egregious privacy violations including the Facebook Cambridge Analytica scandal and the more recent WhatsApp Pegasus Spyware scandal.

Given this, you might be surprised to hear me say that I am generally optimistic that we will get these privacy issues resolved, at least narrowly in the context of digital therapeutic apps.   I'm not making any promises for other apps on your phone or god forbid, Facebook! You're on your own there.....  

---

/fda.png

So here's why I'm optimistic.  In the last five years, the FDA has recognized both the potential benefits and risks to public health posed by digital therapeutics.  In response, the FDA has begun to regulate software, including smartphone apps, as it does other medical devices if the purpose of that software is to prevent, manage, or treat disease. 

This means that the FDA now evaluates the effectiveness and risks, including privacy risks, of digital therapeutics before clearing them for use with patients. 

These FDA policy changes are huge and they begin to situate digital therapeutics squarely within healthcare, where privacy protections have been considered paramount.  

This FDA guidance was also designed to provide the clarity and predictability necessary to stimulate further development, innovation, and investment in digital therapeutics.  

And, in fact, the FDA has already followed through and recently cleared two new digital therapeutics to help people manage and treat substance use disorders.  

---

<!-- still a bit of a rough transistion-->

<!-- slide that says:  “delivering the right treatments, at the right time, to the right person, every time”-->
<!--Talk with Kortney about attractive font and layout on slide for this and next panel-->

Digital therapeutics are here today.  

And as they begin to add personal sensing capabilities, we can start to imagine what precision mental healthcare might look like — “delivering the right treatments, at the right time, to the right person, every time”

My dad did not receive the mental healthcare he needed.  Neither did Victor Kittleson.  In large part, my work now is driven so that others don't suffer similarly.  

My hope is that digital therapeutics can help to break down barriers so that we can begin to provide mental healthcare that is accessible, acceptable, and available 

<!--I havent used the term precision mental healthcare anywhere else.  But the name is somewhat self-defining?-->

---

<!-- Talk with Kortney about adding final line to above but in red?..    ".... and for all of us!"-->

**for all of us**.  

Thank you.